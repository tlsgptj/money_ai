{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 595,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08403361344537816,
      "grad_norm": 1.2168179750442505,
      "learning_rate": 0.00039394957983193284,
      "loss": 1.6336,
      "step": 10
    },
    {
      "epoch": 0.16806722689075632,
      "grad_norm": 1.3798516988754272,
      "learning_rate": 0.00038722689075630255,
      "loss": 1.4323,
      "step": 20
    },
    {
      "epoch": 0.25210084033613445,
      "grad_norm": 1.2646069526672363,
      "learning_rate": 0.00038050420168067226,
      "loss": 1.4078,
      "step": 30
    },
    {
      "epoch": 0.33613445378151263,
      "grad_norm": 1.3135364055633545,
      "learning_rate": 0.000373781512605042,
      "loss": 1.1334,
      "step": 40
    },
    {
      "epoch": 0.42016806722689076,
      "grad_norm": 1.3661746978759766,
      "learning_rate": 0.0003670588235294118,
      "loss": 1.219,
      "step": 50
    },
    {
      "epoch": 0.5042016806722689,
      "grad_norm": 1.4250317811965942,
      "learning_rate": 0.00036033613445378155,
      "loss": 1.2993,
      "step": 60
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 1.3415451049804688,
      "learning_rate": 0.00035361344537815126,
      "loss": 1.1624,
      "step": 70
    },
    {
      "epoch": 0.6722689075630253,
      "grad_norm": 1.1806613206863403,
      "learning_rate": 0.000346890756302521,
      "loss": 1.2445,
      "step": 80
    },
    {
      "epoch": 0.7563025210084033,
      "grad_norm": 1.3825290203094482,
      "learning_rate": 0.0003401680672268908,
      "loss": 1.0448,
      "step": 90
    },
    {
      "epoch": 0.8403361344537815,
      "grad_norm": 1.294143557548523,
      "learning_rate": 0.00033344537815126055,
      "loss": 1.145,
      "step": 100
    },
    {
      "epoch": 0.9243697478991597,
      "grad_norm": 1.178463101387024,
      "learning_rate": 0.00032672268907563026,
      "loss": 1.1871,
      "step": 110
    },
    {
      "epoch": 1.0084033613445378,
      "grad_norm": 1.241786003112793,
      "learning_rate": 0.00032,
      "loss": 1.2045,
      "step": 120
    },
    {
      "epoch": 1.092436974789916,
      "grad_norm": 1.0807652473449707,
      "learning_rate": 0.00031327731092436974,
      "loss": 1.0335,
      "step": 130
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 1.088235855102539,
      "learning_rate": 0.00030655462184873955,
      "loss": 0.9499,
      "step": 140
    },
    {
      "epoch": 1.2605042016806722,
      "grad_norm": 1.797804355621338,
      "learning_rate": 0.00029983193277310926,
      "loss": 0.9038,
      "step": 150
    },
    {
      "epoch": 1.3445378151260505,
      "grad_norm": 1.5013315677642822,
      "learning_rate": 0.000293109243697479,
      "loss": 0.8696,
      "step": 160
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 2.02116322517395,
      "learning_rate": 0.00028638655462184874,
      "loss": 0.8506,
      "step": 170
    },
    {
      "epoch": 1.5126050420168067,
      "grad_norm": 1.0463991165161133,
      "learning_rate": 0.0002796638655462185,
      "loss": 0.9274,
      "step": 180
    },
    {
      "epoch": 1.596638655462185,
      "grad_norm": 1.2820299863815308,
      "learning_rate": 0.00027294117647058827,
      "loss": 0.8699,
      "step": 190
    },
    {
      "epoch": 1.680672268907563,
      "grad_norm": 1.30585515499115,
      "learning_rate": 0.000266218487394958,
      "loss": 0.8022,
      "step": 200
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 1.5260579586029053,
      "learning_rate": 0.00025949579831932774,
      "loss": 0.9017,
      "step": 210
    },
    {
      "epoch": 1.8487394957983194,
      "grad_norm": 1.4369875192642212,
      "learning_rate": 0.0002527731092436975,
      "loss": 0.8571,
      "step": 220
    },
    {
      "epoch": 1.9327731092436975,
      "grad_norm": 1.356303095817566,
      "learning_rate": 0.00024605042016806727,
      "loss": 0.8269,
      "step": 230
    },
    {
      "epoch": 2.0168067226890756,
      "grad_norm": 0.8557519912719727,
      "learning_rate": 0.00023932773109243698,
      "loss": 0.7219,
      "step": 240
    },
    {
      "epoch": 2.100840336134454,
      "grad_norm": 1.4593193531036377,
      "learning_rate": 0.00023260504201680674,
      "loss": 0.7303,
      "step": 250
    },
    {
      "epoch": 2.184873949579832,
      "grad_norm": 1.500885009765625,
      "learning_rate": 0.00022588235294117648,
      "loss": 0.6779,
      "step": 260
    },
    {
      "epoch": 2.26890756302521,
      "grad_norm": 2.117347002029419,
      "learning_rate": 0.00021915966386554624,
      "loss": 0.5655,
      "step": 270
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 2.2475664615631104,
      "learning_rate": 0.00021243697478991598,
      "loss": 0.6733,
      "step": 280
    },
    {
      "epoch": 2.4369747899159666,
      "grad_norm": 1.8357654809951782,
      "learning_rate": 0.00020571428571428572,
      "loss": 0.5478,
      "step": 290
    },
    {
      "epoch": 2.5210084033613445,
      "grad_norm": 2.101494073867798,
      "learning_rate": 0.00019899159663865548,
      "loss": 0.7329,
      "step": 300
    },
    {
      "epoch": 2.6050420168067228,
      "grad_norm": 2.0349748134613037,
      "learning_rate": 0.00019226890756302522,
      "loss": 0.6278,
      "step": 310
    },
    {
      "epoch": 2.689075630252101,
      "grad_norm": 1.6745105981826782,
      "learning_rate": 0.00018554621848739498,
      "loss": 0.6703,
      "step": 320
    },
    {
      "epoch": 2.773109243697479,
      "grad_norm": 1.2885099649429321,
      "learning_rate": 0.00017882352941176472,
      "loss": 0.537,
      "step": 330
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 1.3286703824996948,
      "learning_rate": 0.00017210084033613448,
      "loss": 0.6169,
      "step": 340
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 2.0086963176727295,
      "learning_rate": 0.0001653781512605042,
      "loss": 0.5875,
      "step": 350
    },
    {
      "epoch": 3.0252100840336134,
      "grad_norm": 2.7723002433776855,
      "learning_rate": 0.00015865546218487396,
      "loss": 0.6529,
      "step": 360
    },
    {
      "epoch": 3.1092436974789917,
      "grad_norm": 1.9054450988769531,
      "learning_rate": 0.0001519327731092437,
      "loss": 0.4762,
      "step": 370
    },
    {
      "epoch": 3.19327731092437,
      "grad_norm": 1.7871655225753784,
      "learning_rate": 0.00014521008403361346,
      "loss": 0.3831,
      "step": 380
    },
    {
      "epoch": 3.277310924369748,
      "grad_norm": 2.044956922531128,
      "learning_rate": 0.0001384873949579832,
      "loss": 0.4559,
      "step": 390
    },
    {
      "epoch": 3.361344537815126,
      "grad_norm": 1.7028578519821167,
      "learning_rate": 0.00013176470588235296,
      "loss": 0.4127,
      "step": 400
    },
    {
      "epoch": 3.4453781512605044,
      "grad_norm": 1.670898675918579,
      "learning_rate": 0.0001250420168067227,
      "loss": 0.3696,
      "step": 410
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 1.8320688009262085,
      "learning_rate": 0.00011831932773109244,
      "loss": 0.4202,
      "step": 420
    },
    {
      "epoch": 3.6134453781512605,
      "grad_norm": 2.1558759212493896,
      "learning_rate": 0.0001115966386554622,
      "loss": 0.4509,
      "step": 430
    },
    {
      "epoch": 3.697478991596639,
      "grad_norm": 1.8912602663040161,
      "learning_rate": 0.00010487394957983194,
      "loss": 0.3983,
      "step": 440
    },
    {
      "epoch": 3.7815126050420167,
      "grad_norm": 1.9383225440979004,
      "learning_rate": 9.815126050420168e-05,
      "loss": 0.4576,
      "step": 450
    },
    {
      "epoch": 3.865546218487395,
      "grad_norm": 1.5738600492477417,
      "learning_rate": 9.142857142857143e-05,
      "loss": 0.3649,
      "step": 460
    },
    {
      "epoch": 3.9495798319327733,
      "grad_norm": 1.6363872289657593,
      "learning_rate": 8.470588235294118e-05,
      "loss": 0.4512,
      "step": 470
    },
    {
      "epoch": 4.033613445378151,
      "grad_norm": 1.4044173955917358,
      "learning_rate": 7.798319327731093e-05,
      "loss": 0.3626,
      "step": 480
    },
    {
      "epoch": 4.117647058823529,
      "grad_norm": 1.9206260442733765,
      "learning_rate": 7.126050420168068e-05,
      "loss": 0.2879,
      "step": 490
    },
    {
      "epoch": 4.201680672268908,
      "grad_norm": 2.316720485687256,
      "learning_rate": 6.453781512605043e-05,
      "loss": 0.2874,
      "step": 500
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 4.207404136657715,
      "learning_rate": 5.781512605042018e-05,
      "loss": 0.2705,
      "step": 510
    },
    {
      "epoch": 4.369747899159664,
      "grad_norm": 2.656116247177124,
      "learning_rate": 5.1092436974789914e-05,
      "loss": 0.2615,
      "step": 520
    },
    {
      "epoch": 4.453781512605042,
      "grad_norm": 2.28615403175354,
      "learning_rate": 4.4369747899159665e-05,
      "loss": 0.2555,
      "step": 530
    },
    {
      "epoch": 4.53781512605042,
      "grad_norm": 1.8775027990341187,
      "learning_rate": 3.7647058823529415e-05,
      "loss": 0.3031,
      "step": 540
    },
    {
      "epoch": 4.621848739495798,
      "grad_norm": 2.3470163345336914,
      "learning_rate": 3.0924369747899166e-05,
      "loss": 0.3001,
      "step": 550
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 2.318270444869995,
      "learning_rate": 2.420168067226891e-05,
      "loss": 0.2221,
      "step": 560
    },
    {
      "epoch": 4.7899159663865545,
      "grad_norm": 2.046349287033081,
      "learning_rate": 1.7478991596638656e-05,
      "loss": 0.2879,
      "step": 570
    },
    {
      "epoch": 4.873949579831933,
      "grad_norm": 1.908386468887329,
      "learning_rate": 1.0756302521008405e-05,
      "loss": 0.3485,
      "step": 580
    },
    {
      "epoch": 4.957983193277311,
      "grad_norm": 2.740417003631592,
      "learning_rate": 4.033613445378152e-06,
      "loss": 0.34,
      "step": 590
    }
  ],
  "logging_steps": 10,
  "max_steps": 595,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.704310033907712e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
